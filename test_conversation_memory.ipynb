{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from openai import OpenAI\n",
    "from utils.file_manager import FileManager\n",
    "from utils.conversation import Conversation\n",
    "from utils.llm_manager import Assistant\n",
    "from db.db_manager import MongoDBManager\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_manager = FileManager()\n",
    "conversation_memory_prompt = file_manager.load_md_file('prompts/conversation_memory.md')\n",
    "sales_detector_prompt = file_manager.load_md_file('prompts/sales_detector.md')\n",
    "consentiment_prompt = file_manager.load_md_file('prompts/consentiment.md')\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get(\"THE_OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "#Assistants\n",
    "assistant_memory = Assistant(client=client, base_prompt=conversation_memory_prompt)\n",
    "assistant_sales_detector = Assistant(client=client, base_prompt=sales_detector_prompt)\n",
    "assistant_consentiment = Assistant(client=client, base_prompt=consentiment_prompt)\n",
    "\n",
    "#MongoDB\n",
    "db = MongoDBManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_var_chat_history(resultados: list[dict])-> str:\n",
    "    \"\"\"This function recievesa list of Conversations and for each row (dict), retrieves the questiona dn answer, and generate a string based on that values.\"\"\"\n",
    "    conversacion = \"\"\n",
    "    \n",
    "    for registro in resultados:\n",
    "        question = registro.get(\"question\")\n",
    "        answer = registro.get(\"answer\")\n",
    "        \n",
    "        if question:\n",
    "            conversacion += f\"\\nUser: {question}\"\n",
    "        \n",
    "        if answer:\n",
    "            conversacion += f\"\\nAssistant: {answer}\"\n",
    "    \n",
    "    return conversacion.strip()  # Remove any unnecessary line breaks at the beginning or end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('66ef0c3d1013b8430764f78d'),\n",
       "  'conversation_id': '67c2293c-73d9-46f6-8d7c-5de46d4f87a2',\n",
       "  'question': 'Can I return an item?',\n",
       "  'answer': 'The refund process takes 5-7 business days.',\n",
       "  'sales_intention': False,\n",
       "  'concent': False},\n",
       " {'_id': ObjectId('66ef0c3d1013b8430764f78e'),\n",
       "  'conversation_id': '67c2293c-73d9-46f6-8d7c-5de46d4f87a2',\n",
       "  'question': 'Can I track my order?',\n",
       "  'answer': 'Yes, there is a 1-year warranty on all products.',\n",
       "  'sales_intention': False,\n",
       "  'concent': False}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.buscar_conversaciones_por_id(conversation_id=\"67c2293c-73d9-46f6-8d7c-5de46d4f87a2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = db.buscar_conversaciones_por_id(conversation_id=\"67c2293c-73d9-46f6-8d7c-5de46d4f87a2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_chat_history = format_var_chat_history(resultados=conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'User: Can I return an item?\\nAssistant: The refund process takes 5-7 business days.\\nUser: Can I track my order?\\nAssistant: Yes, there is a 1-year warranty on all products.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given the following conversation and a follow-up question, \\n- summarize the content of the conversation, by keeping **ONLY CONTENT RELEVANT TO THE QUESTION** in order to be understood\\n- For questions in one of the following languages: English, French, German, Italian, Portuguese, or Spanish, you must write the summary in the same language of the question. For instance, a question in Spanish requires a summary in Spanish.\\n- export the follow-up question along with the summary according to the following structure: \\n\\n<relevant_chat_history_synthesis>\\nsummary of relevant chat history\\n</relevant_chat_history_synthesis>\\n\\n<follow_up_input>\\n- follow-up input\\n</follow_up_input>\\n\\nFor the current input:\\nChat History:\\n{var_chat_history}\\nFollow-Up Input: {question}\\nOutput:'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_memory.base_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following conversation and a follow-up question, \n",
      "- summarize the content of the conversation, by keeping **ONLY CONTENT RELEVANT TO THE QUESTION** in order to be understood\n",
      "- For questions in one of the following languages: English, French, German, Italian, Portuguese, or Spanish, you must write the summary in the same language of the question. For instance, a question in Spanish requires a summary in Spanish.\n",
      "- export the follow-up question along with the summary according to the following structure: \n",
      "\n",
      "<relevant_chat_history_synthesis>\n",
      "summary of relevant chat history\n",
      "</relevant_chat_history_synthesis>\n",
      "\n",
      "<follow_up_input>\n",
      "- follow-up input\n",
      "</follow_up_input>\n",
      "\n",
      "For the current input:\n",
      "Chat History:\n",
      "User: Can I return an item?\n",
      "Assistant: The refund process takes 5-7 business days.\n",
      "User: Can I track my order?\n",
      "Assistant: Yes, there is a 1-year warranty on all products.\n",
      "Follow-Up Input: Can you repeat how many days?\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "print(assistant_memory.base_prompt.format(var_chat_history=var_chat_history,question=\"Can you repeat how many days?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question debe ser \"\"\n",
    "#format base_prompt {var_chat_history}: var_chat_history, {question}:question\n",
    "test1 = assistant_memory.assistant_chat_completion_response(prompt=assistant_memory.base_prompt.format(var_chat_history=var_chat_history,question=\"Can you tell if I can tack my order?\"), question=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<relevant_chat_history_synthesis>\n",
      "User: Can I track my order?\n",
      "Assistant: Yes, there is a 1-year warranty on all products.\n",
      "</relevant_chat_history_synthesis>\n",
      "\n",
      "<follow_up_input>\n",
      "- Can you tell if I can tack my order?\n",
      "</follow_up_input>\n"
     ]
    }
   ],
   "source": [
    "print(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
